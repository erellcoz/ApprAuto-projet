{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "# Add the root directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('weld_quality_prediction'), '..')))\n",
    "\n",
    "from data_preprocessing.functions import replace_data, choose_labels, pipeline_training_set\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/welddb.data', sep=' ', header=None)\n",
    "\n",
    "column_names = [\n",
    "    \"Carbon_concentration\",\n",
    "    \"Silicon_concentration\",\n",
    "    \"Manganese_concentration\",\n",
    "    \"Sulphur_concentration\",\n",
    "    \"Phosphorus_concentration\",\n",
    "    \"Nickel_concentration\",\n",
    "    \"Chromium_concentration\",\n",
    "    \"Molybdenum_concentration\",\n",
    "    \"Vanadium_concentration\",\n",
    "    \"Copper_concentration\",\n",
    "    \"Cobalt_concentration\",\n",
    "    \"Tungsten_concentration\",\n",
    "    \"Oxygen_concentration\",\n",
    "    \"Titanium_concentration\",\n",
    "    \"Nitrogen_concentration\",\n",
    "    \"Aluminium_concentration\",\n",
    "    \"Boron_concentration\",\n",
    "    \"Niobium_concentration\",\n",
    "    \"Tin_concentration\",\n",
    "    \"Arsenic_concentration\",\n",
    "    \"Antimony_concentration\",\n",
    "    \"Current\",\n",
    "    \"Voltage\",\n",
    "    \"AC_or_DC\",\n",
    "    \"Electrode_positive_or_negative\",\n",
    "    \"Heat_input\",\n",
    "    \"Interpass_temperature\",\n",
    "    \"Type_of_weld\",\n",
    "    \"Post_weld_heat_treatment_temperature\",\n",
    "    \"Post_weld_heat_treatment_time\",\n",
    "    \"Yield_strength\",\n",
    "    \"Ultimate_tensile_strength\",\n",
    "    \"Elongation\",\n",
    "    \"Reduction_of_Area\",\n",
    "    \"Charpy_temperature\",\n",
    "    \"Charpy_impact_toughness\",\n",
    "    \"Hardness\",\n",
    "    \"50%_FATT\",\n",
    "    \"Primary_ferrite_in_microstructure\",\n",
    "    \"Ferrite_with_second_phase\",\n",
    "    \"Acicular_ferrite\",\n",
    "    \"Martensite\",\n",
    "    \"Ferrite_with_carbide_aggregate\",\n",
    "    \"Weld_ID\"\n",
    "]\n",
    "\n",
    "sulphur_and_phosphorus_columns = [\"Sulphur_concentration\",\"Phosphorus_concentration\"]\n",
    "\n",
    "other_concentration_columns = [\"Carbon_concentration\",\n",
    "        \"Silicon_concentration\",\n",
    "        \"Manganese_concentration\",\n",
    "        \"Nickel_concentration\",\n",
    "        \"Chromium_concentration\",\n",
    "        \"Molybdenum_concentration\",\n",
    "        \"Vanadium_concentration\",\n",
    "        \"Copper_concentration\",\n",
    "        \"Cobalt_concentration\",\n",
    "        \"Tungsten_concentration\",\n",
    "        \"Oxygen_concentration\",\n",
    "        \"Titanium_concentration\",\n",
    "        \"Nitrogen_concentration\",\n",
    "        'Nitrogen_concentration_residual',\n",
    "        \"Aluminium_concentration\",\n",
    "        \"Boron_concentration\",\n",
    "        \"Niobium_concentration\",\n",
    "        \"Tin_concentration\",\n",
    "        \"Arsenic_concentration\",\n",
    "        \"Antimony_concentration\"]\n",
    "\n",
    "label_names = ['Yield_strength', 'Ultimate_tensile_strength', 'Elongation', 'Reduction_of_Area', 'Charpy_temperature', \n",
    "                   'Charpy_impact_toughness', 'Hardness', '50%_FATT', 'Primary_ferrite_in_microstructure', 'Ferrite_with_second_phase', \n",
    "                   'Acicular_ferrite', 'Martensite', 'Ferrite_with_carbide_aggregate', 'Hardness_load']\n",
    "\n",
    "physical_ordinal_properties_columns = [\n",
    "        'Current', \n",
    "        'Voltage',\n",
    "        'Heat_input',\n",
    "        'Interpass_temperature',\n",
    "        'Post_weld_heat_treatment_temperature',\n",
    "        'Post_weld_heat_treatment_time', \n",
    "    ]\n",
    "\n",
    "physical_categorical_properties_columns = [\n",
    "    'AC_or_DC',\n",
    "    'Electrode_positive_or_negative',\n",
    "    'Type_of_weld'\n",
    "]\n",
    "\n",
    "data.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "#Selection of the targets\n",
    "labels_selected = [\"Yield_strength\"]\n",
    "\n",
    "#Replace 'N' value with Nan\n",
    "data = replace_data(data)\n",
    "\n",
    "#Selection fof the data for supervised learning\n",
    "data_with_label = data.copy()\n",
    "data_with_label = data[data_with_label[labels_selected].notna().all(axis=1)]\n",
    "\n",
    "#Separation of features and labels\n",
    "X, y = choose_labels(data_with_label, labels_chosen=labels_selected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camil\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "\n",
    "# Define the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, layers, n_layers, activation=nn.ReLU, dropout=True, dropout_rate=0.5):\n",
    "        super(Net, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "        self.dropout_rate = dropout_rate\n",
    "        for i in range(n_layers):\n",
    "            setattr(self, f'fc{i}', nn.Linear(layers[i][0], layers[i][1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers-1):\n",
    "            x = getattr(self, f'fc{i}')(x)\n",
    "            x = self.activation()(x)\n",
    "            if self.dropout == True:\n",
    "                x = nn.Dropout(self.dropout_rate)(x)\n",
    "        x = getattr(self, f'fc{self.n_layers-1}')(x)\n",
    "        x = self.activation()(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, batch_size, visualize=False):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #  Reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Print the progress of the training\n",
    "        if batch % 10 == 0 and batch != 0 and visualize == True:\n",
    "            loss, current = np.sqrt(loss.item()), batch * batch_size + len(X)\n",
    "            print(f\"Mean loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn, visualize=False):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item() * X.size(0)\n",
    "            total_samples += X.size(0)\n",
    "    test_loss /= total_samples\n",
    "    if visualize == True:\n",
    "        print(f\"Test Error: {np.sqrt(test_loss):>8f} \\n\")\n",
    "    return np.sqrt(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Mean loss: 489.898810  [   44/  702]\n",
      "Mean loss: 491.429102  [   84/  702]\n",
      "Mean loss: 521.849296  [  124/  702]\n",
      "Mean loss: 529.871683  [  164/  702]\n",
      "Mean loss: 532.555191  [  204/  702]\n",
      "Mean loss: 433.059844  [  244/  702]\n",
      "Mean loss: 385.205424  [  284/  702]\n",
      "Mean loss: 436.260530  [  324/  702]\n",
      "Mean loss: 424.701219  [  364/  702]\n",
      "Mean loss: 389.977583  [  404/  702]\n",
      "Mean loss: 360.335239  [  444/  702]\n",
      "Mean loss: 330.368781  [  484/  702]\n",
      "Mean loss: 240.465109  [  524/  702]\n",
      "Mean loss: 149.545934  [  564/  702]\n",
      "Mean loss: 77.302233  [  604/  702]\n",
      "Mean loss: 180.060808  [  644/  702]\n",
      "Mean loss: 94.087569  [  684/  702]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Mean loss: 81.430044  [   44/  702]\n",
      "Mean loss: 91.536120  [   84/  702]\n",
      "Mean loss: 72.784943  [  124/  702]\n",
      "Mean loss: 163.304894  [  164/  702]\n",
      "Mean loss: 72.062049  [  204/  702]\n",
      "Mean loss: 60.452937  [  244/  702]\n",
      "Mean loss: 95.440713  [  284/  702]\n",
      "Mean loss: 78.366109  [  324/  702]\n",
      "Mean loss: 37.787432  [  364/  702]\n",
      "Mean loss: 60.963294  [  404/  702]\n",
      "Mean loss: 86.481311  [  444/  702]\n",
      "Mean loss: 27.164552  [  484/  702]\n",
      "Mean loss: 63.410379  [  524/  702]\n",
      "Mean loss: 142.027155  [  564/  702]\n",
      "Mean loss: 59.412270  [  604/  702]\n",
      "Mean loss: 121.427528  [  644/  702]\n",
      "Mean loss: 59.777146  [  684/  702]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Mean loss: 61.462689  [   44/  702]\n",
      "Mean loss: 56.432192  [   84/  702]\n",
      "Mean loss: 76.107824  [  124/  702]\n",
      "Mean loss: 159.895455  [  164/  702]\n",
      "Mean loss: 71.004229  [  204/  702]\n",
      "Mean loss: 59.405161  [  244/  702]\n",
      "Mean loss: 89.147539  [  284/  702]\n",
      "Mean loss: 78.327500  [  324/  702]\n",
      "Mean loss: 36.431283  [  364/  702]\n",
      "Mean loss: 56.910647  [  404/  702]\n",
      "Mean loss: 87.631542  [  444/  702]\n",
      "Mean loss: 24.966209  [  484/  702]\n",
      "Mean loss: 57.185713  [  524/  702]\n",
      "Mean loss: 144.400918  [  564/  702]\n",
      "Mean loss: 62.430305  [  604/  702]\n",
      "Mean loss: 119.308141  [  644/  702]\n",
      "Mean loss: 52.989390  [  684/  702]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Mean loss: 57.895934  [   44/  702]\n",
      "Mean loss: 61.761287  [   84/  702]\n",
      "Mean loss: 81.882606  [  124/  702]\n",
      "Mean loss: 154.900258  [  164/  702]\n",
      "Mean loss: 68.199071  [  204/  702]\n",
      "Mean loss: 58.022124  [  244/  702]\n",
      "Mean loss: 87.978929  [  284/  702]\n",
      "Mean loss: 78.157003  [  324/  702]\n",
      "Mean loss: 36.592903  [  364/  702]\n",
      "Mean loss: 56.689111  [  404/  702]\n",
      "Mean loss: 87.046975  [  444/  702]\n",
      "Mean loss: 25.145834  [  484/  702]\n",
      "Mean loss: 55.902654  [  524/  702]\n",
      "Mean loss: 144.320397  [  564/  702]\n",
      "Mean loss: 65.488455  [  604/  702]\n",
      "Mean loss: 119.743680  [  644/  702]\n",
      "Mean loss: 49.246009  [  684/  702]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Mean loss: 56.306868  [   44/  702]\n",
      "Mean loss: 60.137300  [   84/  702]\n",
      "Mean loss: 84.247676  [  124/  702]\n",
      "Mean loss: 150.884184  [  164/  702]\n",
      "Mean loss: 63.379322  [  204/  702]\n",
      "Mean loss: 57.182934  [  244/  702]\n",
      "Mean loss: 86.862033  [  284/  702]\n",
      "Mean loss: 77.124804  [  324/  702]\n",
      "Mean loss: 36.611371  [  364/  702]\n",
      "Mean loss: 56.951502  [  404/  702]\n",
      "Mean loss: 86.001039  [  444/  702]\n",
      "Mean loss: 25.408462  [  484/  702]\n",
      "Mean loss: 55.835653  [  524/  702]\n",
      "Mean loss: 143.312350  [  564/  702]\n",
      "Mean loss: 68.083223  [  604/  702]\n",
      "Mean loss: 120.050787  [  644/  702]\n",
      "Mean loss: 46.525229  [  684/  702]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Mean loss: 55.395749  [   44/  702]\n",
      "Mean loss: 59.927347  [   84/  702]\n",
      "Mean loss: 85.731116  [  124/  702]\n",
      "Mean loss: 147.417840  [  164/  702]\n",
      "Mean loss: 58.854151  [  204/  702]\n",
      "Mean loss: 56.649152  [  244/  702]\n",
      "Mean loss: 85.668730  [  284/  702]\n",
      "Mean loss: 76.078801  [  324/  702]\n",
      "Mean loss: 36.583286  [  364/  702]\n",
      "Mean loss: 57.340003  [  404/  702]\n",
      "Mean loss: 84.918248  [  444/  702]\n",
      "Mean loss: 25.789206  [  484/  702]\n",
      "Mean loss: 56.074322  [  524/  702]\n",
      "Mean loss: 142.135526  [  564/  702]\n",
      "Mean loss: 70.198108  [  604/  702]\n",
      "Mean loss: 120.334341  [  644/  702]\n",
      "Mean loss: 44.588409  [  684/  702]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Mean loss: 54.753650  [   44/  702]\n",
      "Mean loss: 59.819118  [   84/  702]\n",
      "Mean loss: 86.748362  [  124/  702]\n",
      "Mean loss: 144.257311  [  164/  702]\n",
      "Mean loss: 54.903411  [  204/  702]\n",
      "Mean loss: 56.286776  [  244/  702]\n",
      "Mean loss: 84.494447  [  284/  702]\n",
      "Mean loss: 75.161798  [  324/  702]\n",
      "Mean loss: 36.555850  [  364/  702]\n",
      "Mean loss: 57.775776  [  404/  702]\n",
      "Mean loss: 83.920442  [  444/  702]\n",
      "Mean loss: 26.298203  [  484/  702]\n",
      "Mean loss: 56.397145  [  524/  702]\n",
      "Mean loss: 141.031198  [  564/  702]\n",
      "Mean loss: 71.953792  [  604/  702]\n",
      "Mean loss: 120.644700  [  644/  702]\n",
      "Mean loss: 43.368403  [  684/  702]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Mean loss: 54.333791  [   44/  702]\n",
      "Mean loss: 59.796746  [   84/  702]\n",
      "Mean loss: 87.512605  [  124/  702]\n",
      "Mean loss: 141.332719  [  164/  702]\n",
      "Mean loss: 51.553579  [  204/  702]\n",
      "Mean loss: 56.013657  [  244/  702]\n",
      "Mean loss: 83.387163  [  284/  702]\n",
      "Mean loss: 74.375725  [  324/  702]\n",
      "Mean loss: 36.535418  [  364/  702]\n",
      "Mean loss: 58.237852  [  404/  702]\n",
      "Mean loss: 83.016991  [  444/  702]\n",
      "Mean loss: 26.901646  [  484/  702]\n",
      "Mean loss: 56.762677  [  524/  702]\n",
      "Mean loss: 140.029601  [  564/  702]\n",
      "Mean loss: 73.391116  [  604/  702]\n",
      "Mean loss: 120.991271  [  644/  702]\n",
      "Mean loss: 42.769190  [  684/  702]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Mean loss: 54.062599  [   44/  702]\n",
      "Mean loss: 59.798751  [   84/  702]\n",
      "Mean loss: 88.107703  [  124/  702]\n",
      "Mean loss: 138.616088  [  164/  702]\n",
      "Mean loss: 48.742773  [  204/  702]\n",
      "Mean loss: 55.799988  [  244/  702]\n",
      "Mean loss: 82.377306  [  284/  702]\n",
      "Mean loss: 73.712020  [  324/  702]\n",
      "Mean loss: 36.516782  [  364/  702]\n",
      "Mean loss: 58.708384  [  404/  702]\n",
      "Mean loss: 82.200516  [  444/  702]\n",
      "Mean loss: 27.564287  [  484/  702]\n",
      "Mean loss: 57.152282  [  524/  702]\n",
      "Mean loss: 139.128383  [  564/  702]\n",
      "Mean loss: 74.558342  [  604/  702]\n",
      "Mean loss: 121.352739  [  644/  702]\n",
      "Mean loss: 42.656625  [  684/  702]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Mean loss: 53.918434  [   44/  702]\n",
      "Mean loss: 59.800984  [   84/  702]\n",
      "Mean loss: 88.590708  [  124/  702]\n",
      "Mean loss: 136.092426  [  164/  702]\n",
      "Mean loss: 46.402954  [  204/  702]\n",
      "Mean loss: 55.626736  [  244/  702]\n",
      "Mean loss: 81.465738  [  284/  702]\n",
      "Mean loss: 73.150670  [  324/  702]\n",
      "Mean loss: 36.496244  [  364/  702]\n",
      "Mean loss: 59.178957  [  404/  702]\n",
      "Mean loss: 81.459310  [  444/  702]\n",
      "Mean loss: 28.259718  [  484/  702]\n",
      "Mean loss: 57.560292  [  524/  702]\n",
      "Mean loss: 138.312444  [  564/  702]\n",
      "Mean loss: 75.489927  [  604/  702]\n",
      "Mean loss: 121.716006  [  644/  702]\n",
      "Mean loss: 42.884352  [  684/  702]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Mean loss: 53.869933  [   44/  702]\n",
      "Mean loss: 59.789458  [   84/  702]\n",
      "Mean loss: 88.994105  [  124/  702]\n",
      "Mean loss: 133.747204  [  164/  702]\n",
      "Mean loss: 44.469689  [  204/  702]\n",
      "Mean loss: 55.484250  [  244/  702]\n",
      "Mean loss: 80.646733  [  284/  702]\n",
      "Mean loss: 72.674947  [  324/  702]\n",
      "Mean loss: 36.471101  [  364/  702]\n",
      "Mean loss: 59.642907  [  404/  702]\n",
      "Mean loss: 80.782386  [  444/  702]\n",
      "Mean loss: 28.968053  [  484/  702]\n",
      "Mean loss: 57.979194  [  524/  702]\n",
      "Mean loss: 137.569989  [  564/  702]\n",
      "Mean loss: 76.220595  [  604/  702]\n",
      "Mean loss: 122.067788  [  644/  702]\n",
      "Mean loss: 43.312714  [  684/  702]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Mean loss: 53.898965  [   44/  702]\n",
      "Mean loss: 59.752280  [   84/  702]\n",
      "Mean loss: 89.341435  [  124/  702]\n",
      "Mean loss: 131.567674  [  164/  702]\n",
      "Mean loss: 42.885516  [  204/  702]\n",
      "Mean loss: 55.365458  [  244/  702]\n",
      "Mean loss: 79.908490  [  284/  702]\n",
      "Mean loss: 72.268924  [  324/  702]\n",
      "Mean loss: 36.440019  [  364/  702]\n",
      "Mean loss: 60.096368  [  404/  702]\n",
      "Mean loss: 80.159174  [  444/  702]\n",
      "Mean loss: 29.676063  [  484/  702]\n",
      "Mean loss: 58.403662  [  524/  702]\n",
      "Mean loss: 136.889882  [  564/  702]\n",
      "Mean loss: 76.778970  [  604/  702]\n",
      "Mean loss: 122.400482  [  644/  702]\n",
      "Mean loss: 43.827060  [  684/  702]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Mean loss: 53.986146  [   44/  702]\n",
      "Mean loss: 59.683972  [   84/  702]\n",
      "Mean loss: 89.647111  [  124/  702]\n",
      "Mean loss: 129.540436  [  164/  702]\n",
      "Mean loss: 41.599738  [  204/  702]\n",
      "Mean loss: 55.265671  [  244/  702]\n",
      "Mean loss: 79.239075  [  284/  702]\n",
      "Mean loss: 71.919742  [  324/  702]\n",
      "Mean loss: 36.402441  [  364/  702]\n",
      "Mean loss: 60.536382  [  404/  702]\n",
      "Mean loss: 79.581069  [  444/  702]\n",
      "Mean loss: 30.374247  [  484/  702]\n",
      "Mean loss: 58.827841  [  524/  702]\n",
      "Mean loss: 136.263460  [  564/  702]\n",
      "Mean loss: 77.191308  [  604/  702]\n",
      "Mean loss: 122.708126  [  644/  702]\n",
      "Mean loss: 44.343157  [  684/  702]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Mean loss: 54.116851  [   44/  702]\n",
      "Mean loss: 59.581616  [   84/  702]\n",
      "Mean loss: 89.920956  [  124/  702]\n",
      "Mean loss: 127.652459  [  164/  702]\n",
      "Mean loss: 40.568166  [  204/  702]\n",
      "Mean loss: 55.181264  [  244/  702]\n",
      "Mean loss: 78.627419  [  284/  702]\n",
      "Mean loss: 71.616911  [  324/  702]\n",
      "Mean loss: 36.358438  [  364/  702]\n",
      "Mean loss: 60.960524  [  404/  702]\n",
      "Mean loss: 79.040054  [  444/  702]\n",
      "Mean loss: 31.056144  [  484/  702]\n",
      "Mean loss: 59.246712  [  524/  702]\n",
      "Mean loss: 135.683923  [  564/  702]\n",
      "Mean loss: 77.480211  [  604/  702]\n",
      "Mean loss: 122.987907  [  644/  702]\n",
      "Mean loss: 44.807436  [  684/  702]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Mean loss: 54.277769  [   44/  702]\n",
      "Mean loss: 59.446468  [   84/  702]\n",
      "Mean loss: 90.169318  [  124/  702]\n",
      "Mean loss: 125.890787  [  164/  702]\n",
      "Mean loss: 39.752464  [  204/  702]\n",
      "Mean loss: 55.109280  [  244/  702]\n",
      "Mean loss: 78.064720  [  284/  702]\n",
      "Mean loss: 71.351942  [  324/  702]\n",
      "Mean loss: 36.308399  [  364/  702]\n",
      "Mean loss: 61.367577  [  404/  702]\n",
      "Mean loss: 78.531368  [  444/  702]\n",
      "Mean loss: 31.716838  [  484/  702]\n",
      "Mean loss: 59.655726  [  524/  702]\n",
      "Mean loss: 135.145632  [  564/  702]\n",
      "Mean loss: 77.665200  [  604/  702]\n",
      "Mean loss: 123.238661  [  644/  702]\n",
      "Mean loss: 45.192418  [  684/  702]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Mean loss: 54.458474  [   44/  702]\n",
      "Mean loss: 59.281967  [   84/  702]\n",
      "Mean loss: 90.396190  [  124/  702]\n",
      "Mean loss: 124.242659  [  164/  702]\n",
      "Mean loss: 39.119313  [  204/  702]\n",
      "Mean loss: 55.047232  [  244/  702]\n",
      "Mean loss: 77.544783  [  284/  702]\n",
      "Mean loss: 71.118389  [  324/  702]\n",
      "Mean loss: 36.252960  [  364/  702]\n",
      "Mean loss: 61.756274  [  404/  702]\n",
      "Mean loss: 78.050834  [  444/  702]\n",
      "Mean loss: 32.352539  [  484/  702]\n",
      "Mean loss: 60.051040  [  524/  702]\n",
      "Mean loss: 134.644650  [  564/  702]\n",
      "Mean loss: 77.763071  [  604/  702]\n",
      "Mean loss: 123.460892  [  644/  702]\n",
      "Mean loss: 45.489783  [  684/  702]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Mean loss: 54.650146  [   44/  702]\n",
      "Mean loss: 59.093486  [   84/  702]\n",
      "Mean loss: 90.603769  [  124/  702]\n",
      "Mean loss: 122.695937  [  164/  702]\n",
      "Mean loss: 38.639895  [  204/  702]\n",
      "Mean loss: 54.993030  [  244/  702]\n",
      "Mean loss: 77.063184  [  284/  702]\n",
      "Mean loss: 70.910840  [  324/  702]\n",
      "Mean loss: 36.193178  [  364/  702]\n",
      "Mean loss: 62.125656  [  404/  702]\n",
      "Mean loss: 77.596154  [  444/  702]\n",
      "Mean loss: 32.960318  [  484/  702]\n",
      "Mean loss: 60.429285  [  524/  702]\n",
      "Mean loss: 134.177740  [  564/  702]\n",
      "Mean loss: 77.788023  [  604/  702]\n",
      "Mean loss: 123.655887  [  644/  702]\n",
      "Mean loss: 45.703705  [  684/  702]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Mean loss: 54.846016  [   44/  702]\n",
      "Mean loss: 58.887391  [   84/  702]\n",
      "Mean loss: 90.793405  [  124/  702]\n",
      "Mean loss: 121.239420  [  164/  702]\n",
      "Mean loss: 38.289272  [  204/  702]\n",
      "Mean loss: 54.944912  [  244/  702]\n",
      "Mean loss: 76.617171  [  284/  702]\n",
      "Mean loss: 70.725275  [  324/  702]\n",
      "Mean loss: 36.129975  [  364/  702]\n",
      "Mean loss: 62.475280  [  404/  702]\n",
      "Mean loss: 77.165767  [  444/  702]\n",
      "Mean loss: 33.537640  [  484/  702]\n",
      "Mean loss: 60.787895  [  524/  702]\n",
      "Mean loss: 133.742815  [  564/  702]\n",
      "Mean loss: 77.752462  [  604/  702]\n",
      "Mean loss: 123.825636  [  644/  702]\n",
      "Mean loss: 45.844903  [  684/  702]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Mean loss: 55.040610  [   44/  702]\n",
      "Mean loss: 58.669830  [   84/  702]\n",
      "Mean loss: 90.965760  [  124/  702]\n",
      "Mean loss: 119.862853  [  164/  702]\n",
      "Mean loss: 38.045888  [  204/  702]\n",
      "Mean loss: 54.901543  [  244/  702]\n",
      "Mean loss: 76.204655  [  284/  702]\n",
      "Mean loss: 70.558351  [  324/  702]\n",
      "Mean loss: 36.064538  [  364/  702]\n",
      "Mean loss: 62.804780  [  404/  702]\n",
      "Mean loss: 76.759014  [  444/  702]\n",
      "Mean loss: 34.082722  [  484/  702]\n",
      "Mean loss: 61.124800  [  524/  702]\n",
      "Mean loss: 133.338217  [  564/  702]\n",
      "Mean loss: 77.666693  [  604/  702]\n",
      "Mean loss: 123.972279  [  644/  702]\n",
      "Mean loss: 45.926638  [  684/  702]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Mean loss: 55.230014  [   44/  702]\n",
      "Mean loss: 58.446711  [   84/  702]\n",
      "Mean loss: 91.121019  [  124/  702]\n",
      "Mean loss: 118.557303  [  164/  702]\n",
      "Mean loss: 37.890918  [  204/  702]\n",
      "Mean loss: 54.861789  [  244/  702]\n",
      "Mean loss: 75.824343  [  284/  702]\n",
      "Mean loss: 70.407571  [  324/  702]\n",
      "Mean loss: 35.997903  [  364/  702]\n",
      "Mean loss: 63.114164  [  404/  702]\n",
      "Mean loss: 76.375678  [  444/  702]\n",
      "Mean loss: 34.593914  [  484/  702]\n",
      "Mean loss: 61.438478  [  524/  702]\n",
      "Mean loss: 132.962952  [  564/  702]\n",
      "Mean loss: 77.539585  [  604/  702]\n",
      "Mean loss: 124.097960  [  644/  702]\n",
      "Mean loss: 45.961917  [  684/  702]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Mean loss: 55.411165  [   44/  702]\n",
      "Mean loss: 58.223019  [   84/  702]\n",
      "Mean loss: 91.259519  [  124/  702]\n",
      "Mean loss: 117.315031  [  164/  702]\n",
      "Mean loss: 37.808054  [  204/  702]\n",
      "Mean loss: 54.824828  [  244/  702]\n",
      "Mean loss: 75.474958  [  284/  702]\n",
      "Mean loss: 70.270911  [  324/  702]\n",
      "Mean loss: 35.930969  [  364/  702]\n",
      "Mean loss: 63.403412  [  404/  702]\n",
      "Mean loss: 76.015598  [  444/  702]\n",
      "Mean loss: 35.070211  [  484/  702]\n",
      "Mean loss: 61.727958  [  524/  702]\n",
      "Mean loss: 132.616156  [  564/  702]\n",
      "Mean loss: 77.378846  [  604/  702]\n",
      "Mean loss: 124.204752  [  644/  702]\n",
      "Mean loss: 45.962097  [  684/  702]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Mean loss: 55.582300  [   44/  702]\n",
      "Mean loss: 58.003022  [   84/  702]\n",
      "Mean loss: 91.381316  [  124/  702]\n",
      "Mean loss: 116.129213  [  164/  702]\n",
      "Mean loss: 37.783008  [  204/  702]\n",
      "Mean loss: 54.789993  [  244/  702]\n",
      "Mean loss: 75.155217  [  284/  702]\n",
      "Mean loss: 70.146815  [  324/  702]\n",
      "Mean loss: 35.864682  [  364/  702]\n",
      "Mean loss: 63.672772  [  404/  702]\n",
      "Mean loss: 75.678639  [  444/  702]\n",
      "Mean loss: 35.510964  [  484/  702]\n",
      "Mean loss: 61.992756  [  524/  702]\n",
      "Mean loss: 132.297376  [  564/  702]\n",
      "Mean loss: 77.190891  [  604/  702]\n",
      "Mean loss: 124.294250  [  644/  702]\n",
      "Mean loss: 45.936381  [  684/  702]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Mean loss: 55.741756  [   44/  702]\n",
      "Mean loss: 57.789763  [   84/  702]\n",
      "Mean loss: 91.486893  [  124/  702]\n",
      "Mean loss: 114.994187  [  164/  702]\n",
      "Mean loss: 37.803155  [  204/  702]\n",
      "Mean loss: 54.756889  [  244/  702]\n",
      "Mean loss: 74.863799  [  284/  702]\n",
      "Mean loss: 70.034171  [  324/  702]\n",
      "Mean loss: 35.799605  [  364/  702]\n",
      "Mean loss: 63.922637  [  404/  702]\n",
      "Mean loss: 75.364570  [  444/  702]\n",
      "Mean loss: 35.915892  [  484/  702]\n",
      "Mean loss: 62.232857  [  524/  702]\n",
      "Mean loss: 132.006000  [  564/  702]\n",
      "Mean loss: 76.981392  [  604/  702]\n",
      "Mean loss: 124.368153  [  644/  702]\n",
      "Mean loss: 45.891952  [  684/  702]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Mean loss: 55.889026  [   44/  702]\n",
      "Mean loss: 57.585755  [   84/  702]\n",
      "Mean loss: 91.576412  [  124/  702]\n",
      "Mean loss: 113.905028  [  164/  702]\n",
      "Mean loss: 37.857579  [  204/  702]\n",
      "Mean loss: 54.725134  [  244/  702]\n",
      "Mean loss: 74.599212  [  284/  702]\n",
      "Mean loss: 69.932089  [  324/  702]\n",
      "Mean loss: 35.736351  [  364/  702]\n",
      "Mean loss: 64.153396  [  404/  702]\n",
      "Mean loss: 75.073063  [  444/  702]\n",
      "Mean loss: 36.285213  [  484/  702]\n",
      "Mean loss: 62.448537  [  524/  702]\n",
      "Mean loss: 131.741476  [  564/  702]\n",
      "Mean loss: 76.755392  [  604/  702]\n",
      "Mean loss: 124.427784  [  644/  702]\n",
      "Mean loss: 45.834139  [  684/  702]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Mean loss: 56.023579  [   44/  702]\n",
      "Mean loss: 57.392344  [   84/  702]\n",
      "Mean loss: 91.650709  [  124/  702]\n",
      "Mean loss: 112.857479  [  164/  702]\n",
      "Mean loss: 37.936705  [  204/  702]\n",
      "Mean loss: 54.694397  [  244/  702]\n",
      "Mean loss: 74.359580  [  284/  702]\n",
      "Mean loss: 69.839859  [  324/  702]\n",
      "Mean loss: 35.675235  [  364/  702]\n",
      "Mean loss: 64.365708  [  404/  702]\n",
      "Mean loss: 74.803564  [  444/  702]\n",
      "Mean loss: 36.619505  [  484/  702]\n",
      "Mean loss: 62.640533  [  524/  702]\n",
      "Mean loss: 131.503082  [  564/  702]\n",
      "Mean loss: 76.517002  [  604/  702]\n",
      "Mean loss: 124.474324  [  644/  702]\n",
      "Mean loss: 45.767020  [  684/  702]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Mean loss: 56.145428  [   44/  702]\n",
      "Mean loss: 57.210749  [   84/  702]\n",
      "Mean loss: 91.710328  [  124/  702]\n",
      "Mean loss: 111.847924  [  164/  702]\n",
      "Mean loss: 38.032062  [  204/  702]\n",
      "Mean loss: 54.664515  [  244/  702]\n",
      "Mean loss: 74.143455  [  284/  702]\n",
      "Mean loss: 69.756976  [  324/  702]\n",
      "Mean loss: 35.616525  [  364/  702]\n",
      "Mean loss: 64.560201  [  404/  702]\n",
      "Mean loss: 74.555227  [  444/  702]\n",
      "Mean loss: 36.919840  [  484/  702]\n",
      "Mean loss: 62.809760  [  524/  702]\n",
      "Mean loss: 131.289934  [  564/  702]\n",
      "Mean loss: 76.269913  [  604/  702]\n",
      "Mean loss: 124.508938  [  644/  702]\n",
      "Mean loss: 45.693514  [  684/  702]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Mean loss: 56.254774  [   44/  702]\n",
      "Mean loss: 57.041363  [   84/  702]\n",
      "Mean loss: 91.756354  [  124/  702]\n",
      "Mean loss: 110.873230  [  164/  702]\n",
      "Mean loss: 38.136645  [  204/  702]\n",
      "Mean loss: 54.635145  [  244/  702]\n",
      "Mean loss: 73.948828  [  284/  702]\n",
      "Mean loss: 69.682959  [  324/  702]\n",
      "Mean loss: 35.560351  [  364/  702]\n",
      "Mean loss: 64.737699  [  404/  702]\n",
      "Mean loss: 74.327151  [  444/  702]\n",
      "Mean loss: 37.187587  [  484/  702]\n",
      "Mean loss: 62.957536  [  524/  702]\n",
      "Mean loss: 131.100972  [  564/  702]\n",
      "Mean loss: 76.017290  [  604/  702]\n",
      "Mean loss: 124.532677  [  644/  702]\n",
      "Mean loss: 45.615833  [  684/  702]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Mean loss: 56.352028  [   44/  702]\n",
      "Mean loss: 56.884458  [   84/  702]\n",
      "Mean loss: 91.789730  [  124/  702]\n",
      "Mean loss: 109.930536  [  164/  702]\n",
      "Mean loss: 38.244332  [  204/  702]\n",
      "Mean loss: 54.606091  [  244/  702]\n",
      "Mean loss: 73.773887  [  284/  702]\n",
      "Mean loss: 69.617562  [  324/  702]\n",
      "Mean loss: 35.506753  [  364/  702]\n",
      "Mean loss: 64.898998  [  404/  702]\n",
      "Mean loss: 74.118208  [  444/  702]\n",
      "Mean loss: 37.424476  [  484/  702]\n",
      "Mean loss: 63.085275  [  524/  702]\n",
      "Mean loss: 130.934800  [  564/  702]\n",
      "Mean loss: 75.761789  [  604/  702]\n",
      "Mean loss: 124.546482  [  644/  702]\n",
      "Mean loss: 45.535652  [  684/  702]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Mean loss: 56.437705  [   44/  702]\n",
      "Mean loss: 56.739765  [   84/  702]\n",
      "Mean loss: 91.811777  [  124/  702]\n",
      "Mean loss: 109.017505  [  164/  702]\n",
      "Mean loss: 38.350180  [  204/  702]\n",
      "Mean loss: 54.577204  [  244/  702]\n",
      "Mean loss: 73.616756  [  284/  702]\n",
      "Mean loss: 69.560275  [  324/  702]\n",
      "Mean loss: 35.455737  [  364/  702]\n",
      "Mean loss: 65.045184  [  404/  702]\n",
      "Mean loss: 73.926966  [  444/  702]\n",
      "Mean loss: 37.632463  [  484/  702]\n",
      "Mean loss: 63.194597  [  524/  702]\n",
      "Mean loss: 130.789878  [  564/  702]\n",
      "Mean loss: 75.505733  [  604/  702]\n",
      "Mean loss: 124.551539  [  644/  702]\n",
      "Mean loss: 45.454213  [  684/  702]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Mean loss: 56.512586  [   44/  702]\n",
      "Mean loss: 56.607085  [   84/  702]\n",
      "Mean loss: 91.823561  [  124/  702]\n",
      "Mean loss: 108.131990  [  164/  702]\n",
      "Mean loss: 38.450487  [  204/  702]\n",
      "Mean loss: 54.548245  [  244/  702]\n",
      "Mean loss: 73.475628  [  284/  702]\n",
      "Mean loss: 69.510791  [  324/  702]\n",
      "Mean loss: 35.407264  [  364/  702]\n",
      "Mean loss: 65.177230  [  404/  702]\n",
      "Mean loss: 73.752138  [  444/  702]\n",
      "Mean loss: 37.813904  [  484/  702]\n",
      "Mean loss: 63.287183  [  524/  702]\n",
      "Mean loss: 130.664625  [  564/  702]\n",
      "Mean loss: 75.251009  [  604/  702]\n",
      "Mean loss: 124.548485  [  644/  702]\n",
      "Mean loss: 45.372520  [  684/  702]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Mean loss: 56.577171  [   44/  702]\n",
      "Mean loss: 56.485693  [   84/  702]\n",
      "Mean loss: 91.826454  [  124/  702]\n",
      "Mean loss: 107.272311  [  164/  702]\n",
      "Mean loss: 38.542470  [  204/  702]\n",
      "Mean loss: 54.519071  [  244/  702]\n",
      "Mean loss: 73.348783  [  284/  702]\n",
      "Mean loss: 69.468701  [  324/  702]\n",
      "Mean loss: 35.361110  [  364/  702]\n",
      "Mean loss: 65.296204  [  404/  702]\n",
      "Mean loss: 73.591985  [  444/  702]\n",
      "Mean loss: 37.971010  [  484/  702]\n",
      "Mean loss: 63.364752  [  524/  702]\n",
      "Mean loss: 130.557100  [  564/  702]\n",
      "Mean loss: 74.999102  [  604/  702]\n",
      "Mean loss: 124.538504  [  644/  702]\n",
      "Mean loss: 45.291269  [  684/  702]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Mean loss: 56.632454  [   44/  702]\n",
      "Mean loss: 56.375013  [   84/  702]\n",
      "Mean loss: 91.821562  [  124/  702]\n",
      "Mean loss: 106.436766  [  164/  702]\n",
      "Mean loss: 38.624188  [  204/  702]\n",
      "Mean loss: 54.489541  [  244/  702]\n",
      "Mean loss: 73.234610  [  284/  702]\n",
      "Mean loss: 69.433379  [  324/  702]\n",
      "Mean loss: 35.317206  [  364/  702]\n",
      "Mean loss: 65.403219  [  404/  702]\n",
      "Mean loss: 73.445076  [  444/  702]\n",
      "Mean loss: 38.106382  [  484/  702]\n",
      "Mean loss: 63.429083  [  524/  702]\n",
      "Mean loss: 130.465303  [  564/  702]\n",
      "Mean loss: 74.751244  [  604/  702]\n",
      "Mean loss: 124.522479  [  644/  702]\n",
      "Mean loss: 45.210967  [  684/  702]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Mean loss: 56.679112  [   44/  702]\n",
      "Mean loss: 56.274272  [   84/  702]\n",
      "Mean loss: 91.810245  [  124/  702]\n",
      "Mean loss: 105.624159  [  164/  702]\n",
      "Mean loss: 38.694504  [  204/  702]\n",
      "Mean loss: 54.459623  [  244/  702]\n",
      "Mean loss: 73.131540  [  284/  702]\n",
      "Mean loss: 69.404312  [  324/  702]\n",
      "Mean loss: 35.275390  [  364/  702]\n",
      "Mean loss: 65.499463  [  404/  702]\n",
      "Mean loss: 73.309696  [  444/  702]\n",
      "Mean loss: 38.222372  [  484/  702]\n",
      "Mean loss: 63.481793  [  524/  702]\n",
      "Mean loss: 130.387389  [  564/  702]\n",
      "Mean loss: 74.508307  [  604/  702]\n",
      "Mean loss: 124.501118  [  644/  702]\n",
      "Mean loss: 45.132073  [  684/  702]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Mean loss: 56.717975  [   44/  702]\n",
      "Mean loss: 56.182725  [   84/  702]\n",
      "Mean loss: 91.793411  [  124/  702]\n",
      "Mean loss: 104.833275  [  164/  702]\n",
      "Mean loss: 38.753125  [  204/  702]\n",
      "Mean loss: 54.429234  [  244/  702]\n",
      "Mean loss: 73.038236  [  284/  702]\n",
      "Mean loss: 69.380930  [  324/  702]\n",
      "Mean loss: 35.235504  [  364/  702]\n",
      "Mean loss: 65.586045  [  404/  702]\n",
      "Mean loss: 73.184358  [  444/  702]\n",
      "Mean loss: 38.321318  [  484/  702]\n",
      "Mean loss: 63.524486  [  524/  702]\n",
      "Mean loss: 130.321380  [  564/  702]\n",
      "Mean loss: 74.271093  [  604/  702]\n",
      "Mean loss: 124.475344  [  644/  702]\n",
      "Mean loss: 45.054788  [  684/  702]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Mean loss: 56.749888  [   44/  702]\n",
      "Mean loss: 56.099334  [   84/  702]\n",
      "Mean loss: 91.772184  [  124/  702]\n",
      "Mean loss: 104.063377  [  164/  702]\n",
      "Mean loss: 38.800264  [  204/  702]\n",
      "Mean loss: 54.398522  [  244/  702]\n",
      "Mean loss: 72.953244  [  284/  702]\n",
      "Mean loss: 69.362576  [  324/  702]\n",
      "Mean loss: 35.197434  [  364/  702]\n",
      "Mean loss: 65.664006  [  404/  702]\n",
      "Mean loss: 73.067696  [  444/  702]\n",
      "Mean loss: 38.405583  [  484/  702]\n",
      "Mean loss: 63.558686  [  524/  702]\n",
      "Mean loss: 130.265467  [  564/  702]\n",
      "Mean loss: 74.039883  [  604/  702]\n",
      "Mean loss: 124.445834  [  644/  702]\n",
      "Mean loss: 44.979287  [  684/  702]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Mean loss: 56.775613  [   44/  702]\n",
      "Mean loss: 56.023393  [   84/  702]\n",
      "Mean loss: 91.747360  [  124/  702]\n",
      "Mean loss: 103.313540  [  164/  702]\n",
      "Mean loss: 38.836298  [  204/  702]\n",
      "Mean loss: 54.367434  [  244/  702]\n",
      "Mean loss: 72.875657  [  284/  702]\n",
      "Mean loss: 69.348714  [  324/  702]\n",
      "Mean loss: 35.160948  [  364/  702]\n",
      "Mean loss: 65.734362  [  404/  702]\n",
      "Mean loss: 72.958227  [  444/  702]\n",
      "Mean loss: 38.477134  [  484/  702]\n",
      "Mean loss: 63.585687  [  524/  702]\n",
      "Mean loss: 130.217966  [  564/  702]\n",
      "Mean loss: 73.815086  [  604/  702]\n",
      "Mean loss: 124.413299  [  644/  702]\n",
      "Mean loss: 44.905587  [  684/  702]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Mean loss: 56.795904  [   44/  702]\n",
      "Mean loss: 55.954015  [   84/  702]\n",
      "Mean loss: 91.719847  [  124/  702]\n",
      "Mean loss: 102.583255  [  164/  702]\n",
      "Mean loss: 38.862175  [  204/  702]\n",
      "Mean loss: 54.336121  [  244/  702]\n",
      "Mean loss: 72.804369  [  284/  702]\n",
      "Mean loss: 69.338581  [  324/  702]\n",
      "Mean loss: 35.125923  [  364/  702]\n",
      "Mean loss: 65.798127  [  404/  702]\n",
      "Mean loss: 72.854836  [  444/  702]\n",
      "Mean loss: 38.537999  [  484/  702]\n",
      "Mean loss: 63.606679  [  524/  702]\n",
      "Mean loss: 130.177298  [  564/  702]\n",
      "Mean loss: 73.596689  [  604/  702]\n",
      "Mean loss: 124.378372  [  644/  702]\n",
      "Mean loss: 44.833876  [  684/  702]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Mean loss: 56.811439  [   44/  702]\n",
      "Mean loss: 55.890492  [   84/  702]\n",
      "Mean loss: 91.690237  [  124/  702]\n",
      "Mean loss: 101.871942  [  164/  702]\n",
      "Mean loss: 38.878867  [  204/  702]\n",
      "Mean loss: 54.304635  [  244/  702]\n",
      "Mean loss: 72.738472  [  284/  702]\n",
      "Mean loss: 69.331701  [  324/  702]\n",
      "Mean loss: 35.092242  [  364/  702]\n",
      "Mean loss: 65.856133  [  404/  702]\n",
      "Mean loss: 72.756463  [  444/  702]\n",
      "Mean loss: 38.589806  [  484/  702]\n",
      "Mean loss: 63.622634  [  524/  702]\n",
      "Mean loss: 130.142290  [  564/  702]\n",
      "Mean loss: 73.384835  [  604/  702]\n",
      "Mean loss: 124.341476  [  644/  702]\n",
      "Mean loss: 44.763929  [  684/  702]\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Mean loss: 56.822946  [   44/  702]\n",
      "Mean loss: 55.831980  [   84/  702]\n",
      "Mean loss: 91.660698  [  124/  702]\n",
      "Mean loss: 101.178302  [  164/  702]\n",
      "Mean loss: 38.887360  [  204/  702]\n",
      "Mean loss: 54.272321  [  244/  702]\n",
      "Mean loss: 72.677940  [  284/  702]\n",
      "Mean loss: 69.327320  [  324/  702]\n",
      "Mean loss: 35.059784  [  364/  702]\n",
      "Mean loss: 65.909325  [  404/  702]\n",
      "Mean loss: 72.662352  [  444/  702]\n",
      "Mean loss: 38.634028  [  484/  702]\n",
      "Mean loss: 63.634638  [  524/  702]\n",
      "Mean loss: 130.111731  [  564/  702]\n",
      "Mean loss: 73.179227  [  604/  702]\n",
      "Mean loss: 124.303356  [  644/  702]\n",
      "Mean loss: 44.695817  [  684/  702]\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Mean loss: 56.830857  [   44/  702]\n",
      "Mean loss: 55.778197  [   84/  702]\n",
      "Mean loss: 91.626886  [  124/  702]\n",
      "Mean loss: 100.504577  [  164/  702]\n",
      "Mean loss: 38.889162  [  204/  702]\n",
      "Mean loss: 54.241681  [  244/  702]\n",
      "Mean loss: 72.620085  [  284/  702]\n",
      "Mean loss: 69.325630  [  324/  702]\n",
      "Mean loss: 35.028485  [  364/  702]\n",
      "Mean loss: 65.957957  [  404/  702]\n",
      "Mean loss: 72.571419  [  444/  702]\n",
      "Mean loss: 38.672121  [  484/  702]\n",
      "Mean loss: 63.643074  [  524/  702]\n",
      "Mean loss: 130.084535  [  564/  702]\n",
      "Mean loss: 72.979770  [  604/  702]\n",
      "Mean loss: 124.263773  [  644/  702]\n",
      "Mean loss: 44.629305  [  684/  702]\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Mean loss: 56.835997  [   44/  702]\n",
      "Mean loss: 55.727530  [   84/  702]\n",
      "Mean loss: 91.593979  [  124/  702]\n",
      "Mean loss: 99.847980  [  164/  702]\n",
      "Mean loss: 38.884750  [  204/  702]\n",
      "Mean loss: 54.210496  [  244/  702]\n",
      "Mean loss: 72.566396  [  284/  702]\n",
      "Mean loss: 69.325655  [  324/  702]\n",
      "Mean loss: 34.998188  [  364/  702]\n",
      "Mean loss: 66.003033  [  404/  702]\n",
      "Mean loss: 72.483464  [  444/  702]\n",
      "Mean loss: 38.705071  [  484/  702]\n",
      "Mean loss: 63.648909  [  524/  702]\n",
      "Mean loss: 130.060277  [  564/  702]\n",
      "Mean loss: 72.786255  [  604/  702]\n",
      "Mean loss: 124.223636  [  644/  702]\n",
      "Mean loss: 44.564485  [  684/  702]\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Mean loss: 56.838497  [   44/  702]\n",
      "Mean loss: 55.680645  [   84/  702]\n",
      "Mean loss: 91.560751  [  124/  702]\n",
      "Mean loss: 99.208843  [  164/  702]\n",
      "Mean loss: 38.875301  [  204/  702]\n",
      "Mean loss: 54.179631  [  244/  702]\n",
      "Mean loss: 72.515728  [  284/  702]\n",
      "Mean loss: 69.327123  [  324/  702]\n",
      "Mean loss: 34.968858  [  364/  702]\n",
      "Mean loss: 66.044929  [  404/  702]\n",
      "Mean loss: 72.397938  [  444/  702]\n",
      "Mean loss: 38.733661  [  484/  702]\n",
      "Mean loss: 63.652464  [  524/  702]\n",
      "Mean loss: 130.038148  [  564/  702]\n",
      "Mean loss: 72.598357  [  604/  702]\n",
      "Mean loss: 124.183108  [  644/  702]\n",
      "Mean loss: 44.501236  [  684/  702]\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Mean loss: 56.839073  [   44/  702]\n",
      "Mean loss: 55.636549  [   84/  702]\n",
      "Mean loss: 91.527340  [  124/  702]\n",
      "Mean loss: 98.587005  [  164/  702]\n",
      "Mean loss: 38.861692  [  204/  702]\n",
      "Mean loss: 54.149129  [  244/  702]\n",
      "Mean loss: 72.467827  [  284/  702]\n",
      "Mean loss: 69.329888  [  324/  702]\n",
      "Mean loss: 34.940442  [  364/  702]\n",
      "Mean loss: 66.084112  [  404/  702]\n",
      "Mean loss: 72.314421  [  444/  702]\n",
      "Mean loss: 38.758774  [  484/  702]\n",
      "Mean loss: 63.654240  [  524/  702]\n",
      "Mean loss: 130.017855  [  564/  702]\n",
      "Mean loss: 72.415967  [  604/  702]\n",
      "Mean loss: 124.142260  [  644/  702]\n",
      "Mean loss: 44.439471  [  684/  702]\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Mean loss: 56.837842  [   44/  702]\n",
      "Mean loss: 55.594892  [   84/  702]\n",
      "Mean loss: 91.493980  [  124/  702]\n",
      "Mean loss: 97.982141  [  164/  702]\n",
      "Mean loss: 38.844721  [  204/  702]\n",
      "Mean loss: 54.119106  [  244/  702]\n",
      "Mean loss: 72.422183  [  284/  702]\n",
      "Mean loss: 69.333529  [  324/  702]\n",
      "Mean loss: 34.912815  [  364/  702]\n",
      "Mean loss: 66.120975  [  404/  702]\n",
      "Mean loss: 72.232751  [  444/  702]\n",
      "Mean loss: 38.781112  [  484/  702]\n",
      "Mean loss: 63.654493  [  524/  702]\n",
      "Mean loss: 129.999023  [  564/  702]\n",
      "Mean loss: 72.238703  [  604/  702]\n",
      "Mean loss: 124.101387  [  644/  702]\n",
      "Mean loss: 44.379154  [  684/  702]\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Mean loss: 56.835391  [   44/  702]\n",
      "Mean loss: 55.555542  [   84/  702]\n",
      "Mean loss: 91.460742  [  124/  702]\n",
      "Mean loss: 97.393993  [  164/  702]\n",
      "Mean loss: 38.825006  [  204/  702]\n",
      "Mean loss: 54.089665  [  244/  702]\n",
      "Mean loss: 72.378687  [  284/  702]\n",
      "Mean loss: 69.338032  [  324/  702]\n",
      "Mean loss: 34.886029  [  364/  702]\n",
      "Mean loss: 66.155789  [  404/  702]\n",
      "Mean loss: 72.152511  [  444/  702]\n",
      "Mean loss: 38.801110  [  484/  702]\n",
      "Mean loss: 63.653561  [  524/  702]\n",
      "Mean loss: 129.981301  [  564/  702]\n",
      "Mean loss: 72.066399  [  604/  702]\n",
      "Mean loss: 124.060611  [  644/  702]\n",
      "Mean loss: 44.320237  [  684/  702]\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Mean loss: 56.831828  [   44/  702]\n",
      "Mean loss: 55.517940  [   84/  702]\n",
      "Mean loss: 91.427716  [  124/  702]\n",
      "Mean loss: 96.822244  [  164/  702]\n",
      "Mean loss: 38.803104  [  204/  702]\n",
      "Mean loss: 54.060854  [  244/  702]\n",
      "Mean loss: 72.337078  [  284/  702]\n",
      "Mean loss: 69.343155  [  324/  702]\n",
      "Mean loss: 34.859949  [  364/  702]\n",
      "Mean loss: 66.188887  [  404/  702]\n",
      "Mean loss: 72.073615  [  444/  702]\n",
      "Mean loss: 38.819268  [  484/  702]\n",
      "Mean loss: 63.651636  [  524/  702]\n",
      "Mean loss: 129.964681  [  564/  702]\n",
      "Mean loss: 71.898746  [  604/  702]\n",
      "Mean loss: 124.019994  [  644/  702]\n",
      "Mean loss: 44.262658  [  684/  702]\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Mean loss: 56.827416  [   44/  702]\n",
      "Mean loss: 55.482027  [   84/  702]\n",
      "Mean loss: 91.395138  [  124/  702]\n",
      "Mean loss: 96.266638  [  164/  702]\n",
      "Mean loss: 38.779574  [  204/  702]\n",
      "Mean loss: 54.032768  [  244/  702]\n",
      "Mean loss: 72.297214  [  284/  702]\n",
      "Mean loss: 69.348612  [  324/  702]\n",
      "Mean loss: 34.834586  [  364/  702]\n",
      "Mean loss: 66.220534  [  404/  702]\n",
      "Mean loss: 71.995972  [  444/  702]\n",
      "Mean loss: 38.835893  [  484/  702]\n",
      "Mean loss: 63.648928  [  524/  702]\n",
      "Mean loss: 129.948886  [  564/  702]\n",
      "Mean loss: 71.735650  [  604/  702]\n",
      "Mean loss: 123.979770  [  644/  702]\n",
      "Mean loss: 44.206346  [  684/  702]\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Mean loss: 56.822389  [   44/  702]\n",
      "Mean loss: 55.447564  [   84/  702]\n",
      "Mean loss: 91.362933  [  124/  702]\n",
      "Mean loss: 95.726896  [  164/  702]\n",
      "Mean loss: 38.754794  [  204/  702]\n",
      "Mean loss: 54.005369  [  244/  702]\n",
      "Mean loss: 72.258947  [  284/  702]\n",
      "Mean loss: 69.354378  [  324/  702]\n",
      "Mean loss: 34.809973  [  364/  702]\n",
      "Mean loss: 66.250829  [  404/  702]\n",
      "Mean loss: 71.919446  [  444/  702]\n",
      "Mean loss: 38.851375  [  484/  702]\n",
      "Mean loss: 63.645506  [  524/  702]\n",
      "Mean loss: 129.933787  [  564/  702]\n",
      "Mean loss: 71.576732  [  604/  702]\n",
      "Mean loss: 123.939856  [  644/  702]\n",
      "Mean loss: 44.151251  [  684/  702]\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Mean loss: 56.816975  [   44/  702]\n",
      "Mean loss: 55.414357  [   84/  702]\n",
      "Mean loss: 91.331176  [  124/  702]\n",
      "Mean loss: 95.202683  [  164/  702]\n",
      "Mean loss: 38.728992  [  204/  702]\n",
      "Mean loss: 53.978731  [  244/  702]\n",
      "Mean loss: 72.222144  [  284/  702]\n",
      "Mean loss: 69.360345  [  324/  702]\n",
      "Mean loss: 34.785907  [  364/  702]\n",
      "Mean loss: 66.280020  [  404/  702]\n",
      "Mean loss: 71.843872  [  444/  702]\n",
      "Mean loss: 38.865864  [  484/  702]\n",
      "Mean loss: 63.641519  [  524/  702]\n",
      "Mean loss: 129.919484  [  564/  702]\n",
      "Mean loss: 71.421897  [  604/  702]\n",
      "Mean loss: 123.900366  [  644/  702]\n",
      "Mean loss: 44.097316  [  684/  702]\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Mean loss: 56.811166  [   44/  702]\n",
      "Mean loss: 55.382309  [   84/  702]\n",
      "Mean loss: 91.299906  [  124/  702]\n",
      "Mean loss: 94.693688  [  164/  702]\n",
      "Mean loss: 38.702590  [  204/  702]\n",
      "Mean loss: 53.952910  [  244/  702]\n",
      "Mean loss: 72.186611  [  284/  702]\n",
      "Mean loss: 69.366402  [  324/  702]\n",
      "Mean loss: 34.762556  [  364/  702]\n",
      "Mean loss: 66.308222  [  404/  702]\n",
      "Mean loss: 71.769270  [  444/  702]\n",
      "Mean loss: 38.879631  [  484/  702]\n",
      "Mean loss: 63.637117  [  524/  702]\n",
      "Mean loss: 129.905735  [  564/  702]\n",
      "Mean loss: 71.271104  [  604/  702]\n",
      "Mean loss: 123.861345  [  644/  702]\n",
      "Mean loss: 44.044528  [  684/  702]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "best_parameters = {'lr': 0.01, 'n_epochs': 50, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}\n",
    "\n",
    "# Define the learning rate\n",
    "lr = 0.01\n",
    "\n",
    "# Activation function\n",
    "activation = nn.ReLU\n",
    "\n",
    "# Define weight decay: L2 regularization. It adds a penalty to the loss function based on the magnitude of the weights, \n",
    "                        # which helps to prevent the weights from becoming too large.\n",
    "weight_decay = 0.01\n",
    "\n",
    "# Dropout: a regularization technique that prevents overfitting by randomly setting a fraction of the input units \n",
    "            # to 0 at each update during training time.\n",
    "dropout = False\n",
    "\n",
    "# Define the number of epochs\n",
    "n_epochs = 50\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Layers\n",
    "layer_def = [4, 4]\n",
    "\n",
    "# Parameters\n",
    "categorical_strategy=\"logistic\"\n",
    "ordinal_strategy=\"mean\"\n",
    "is_PCA=True\n",
    "pca_percent_explained_variance=0.9\n",
    "pca_columns=\"all_ordinals\"\n",
    "\n",
    "\n",
    "def create_and_train(X_train, X_test, y_train, y_test, layer_def, ordinal_strategy, categorical_strategy, is_PCA, pca_percent_explained_variance, \n",
    "                     pca_columns, activation, lr, weight_decay, dropout, n_epochs, batch_size, scaler_strategy=\"standard\", visualize=False):\n",
    "    # Preprocess the data\n",
    "    X_train, X_test, y_train, y_test = pipeline_training_set(training_set=X_train, training_labels=y_train, testing_set=X_test, testing_labels=y_test, \n",
    "                                                            labels_chosen=labels_selected, categorical_strategy=categorical_strategy, \\\n",
    "                                                            ordinal_strategy=ordinal_strategy, is_PCA=is_PCA, \n",
    "                                                            pca_percent_explained_variance=pca_percent_explained_variance, \n",
    "                                                            scaler_strategy=scaler_strategy, pca_columns=pca_columns, less_than_strategy=\"mean\")\n",
    "\n",
    "    # Get the input size\n",
    "    input_size = X_train.shape[1]\n",
    "    \n",
    "    # Convert the data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Set the seed for reproducibility\n",
    "    seed = 42\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Define the model\n",
    "    activation = activation\n",
    "    n_layers = len(layer_def)\n",
    "    layers = [(input_size, layer_def[0])]\n",
    "    for i in range(1, n_layers):\n",
    "        layers.append((layer_def[i-1], layer_def[i]))\n",
    "    layers.append((layer_def[n_layers-1], 1))\n",
    "    \n",
    "    model = Net(layers, n_layers+1, activation=activation, dropout=dropout, dropout_rate=0.2)\n",
    "    \n",
    "    # Get the number of hyperparameters\n",
    "    # num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    # print(f\"Number of hyperparameters: {num_params}\")\n",
    "    # print(\"Number of training data:\", len(X_train))\n",
    "\n",
    "\n",
    "    # Define the loss function\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Create the dataset\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "    # Create the dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # Train the model\n",
    "    for t in range(n_epochs):\n",
    "        if visualize == True:\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer, batch_size, visualize=visualize)\n",
    "    return model, X_test, y_test, test_dataloader, loss_fn\n",
    "\n",
    "model, X_test, y_test, test_dataloader, loss_fn = create_and_train(X_train, X_test, y_train, y_test, layer_def, ordinal_strategy, \n",
    "                                                                   categorical_strategy, is_PCA, pca_percent_explained_variance, pca_columns, \n",
    "                                                                   activation, lr, weight_decay, dropout, n_epochs, batch_size, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 75.573953 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_error = test_loop(test_dataloader, model, loss_fn, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "\n",
    "new_y_test = model(X_test).detach().numpy()\n",
    "\n",
    "# Convert new_y_test to a numpy array for plotting\n",
    "new_y_test_values = new_y_test\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(new_y_test_values, y_test.detach().numpy(), color='blue', label='Predicted vs Actual')\n",
    "plt.plot([new_y_test_values.min(), new_y_test_values.max()], [new_y_test_values.min(), new_y_test_values.max()], 'k--', lw=2, label='Ideal Fit')\n",
    "plt.xlabel('Labeled Yield Strength')\n",
    "plt.ylabel('Predicted Yield Strength')\n",
    "plt.title('Ground truth vs predicted Yield Strength')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding best hyperparameters with grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: lr=0.01, n_epochs=30, batch_size=4, weight_decay=0.01, dropout=False, layer_def=[4, 4], ordinal_strategy=mean, categorical_strategy=logistic, is_PCA=True, pca_percent_explained_variance=0.9, pca_columns=all_ordinals\n",
      "\n",
      " Mean Scores:  85.1193931195358 \n",
      "\n",
      "Testing combination: lr=0.01, n_epochs=40, batch_size=4, weight_decay=0.01, dropout=False, layer_def=[4, 4], ordinal_strategy=mean, categorical_strategy=logistic, is_PCA=True, pca_percent_explained_variance=0.9, pca_columns=all_ordinals\n",
      "\n",
      " Mean Scores:  83.71243562174412 \n",
      "\n",
      "Testing combination: lr=0.01, n_epochs=50, batch_size=4, weight_decay=0.01, dropout=False, layer_def=[4, 4], ordinal_strategy=mean, categorical_strategy=logistic, is_PCA=True, pca_percent_explained_variance=0.9, pca_columns=all_ordinals\n",
      "\n",
      " Mean Scores:  82.85544540008891 \n",
      "\n",
      "Testing combination: lr=0.01, n_epochs=60, batch_size=4, weight_decay=0.01, dropout=False, layer_def=[4, 4], ordinal_strategy=mean, categorical_strategy=logistic, is_PCA=True, pca_percent_explained_variance=0.9, pca_columns=all_ordinals\n",
      "\n",
      " Mean Scores:  82.57674656479229 \n",
      "\n",
      "Testing combination: lr=0.01, n_epochs=70, batch_size=4, weight_decay=0.01, dropout=False, layer_def=[4, 4], ordinal_strategy=mean, categorical_strategy=logistic, is_PCA=True, pca_percent_explained_variance=0.9, pca_columns=all_ordinals\n",
      "\n",
      " Mean Scores:  82.49411931406486 \n",
      "\n",
      "Testing combination: lr=0.01, n_epochs=80, batch_size=4, weight_decay=0.01, dropout=False, layer_def=[4, 4], ordinal_strategy=mean, categorical_strategy=logistic, is_PCA=True, pca_percent_explained_variance=0.9, pca_columns=all_ordinals\n",
      "\n",
      " Mean Scores:  82.76658268135363 \n",
      "\n",
      "Best parameters:  {'lr': 0.01, 'n_epochs': 70, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}\n",
      "Best score:  82.49411931406486\n",
      "Best models:  [{'model': Net(\n",
      "  (fc0): Linear(in_features=31, out_features=4, bias=True)\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'score': 85.1193931195358, 'parameters': {'lr': 0.01, 'n_epochs': 30, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}}, {'model': Net(\n",
      "  (fc0): Linear(in_features=31, out_features=4, bias=True)\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'score': 83.71243562174412, 'parameters': {'lr': 0.01, 'n_epochs': 40, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}}, {'model': Net(\n",
      "  (fc0): Linear(in_features=31, out_features=4, bias=True)\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'score': 82.85544540008891, 'parameters': {'lr': 0.01, 'n_epochs': 50, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}}, {'model': Net(\n",
      "  (fc0): Linear(in_features=31, out_features=4, bias=True)\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'score': 82.57674656479229, 'parameters': {'lr': 0.01, 'n_epochs': 60, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}}, {'model': Net(\n",
      "  (fc0): Linear(in_features=31, out_features=4, bias=True)\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'score': 82.49411931406486, 'parameters': {'lr': 0.01, 'n_epochs': 70, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}}, {'model': Net(\n",
      "  (fc0): Linear(in_features=31, out_features=4, bias=True)\n",
      "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'score': 82.76658268135363, 'parameters': {'lr': 0.01, 'n_epochs': 80, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}}]\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "# Define the learning rate\n",
    "lr = [0.01, 0.001]\n",
    "# Define the number of epochs\n",
    "n_epochs = [30, 40, 50]\n",
    "# Define the batch size\n",
    "batch_size = [4, 8, 16] \n",
    "# Activation functions\n",
    "activation = nn.ReLU\n",
    "# Define the weight decay\n",
    "weight_decay = [0.01, 0.05]\n",
    "# Dropout\n",
    "dropout = [False, True]\n",
    "# Layers\n",
    "layer_def = [[4], [8], [16], [4, 4], [8, 8], [16, 16]]\n",
    "# Parameters\n",
    "categorical_strategy = [\"most_frequent\", \"logistic\"]\n",
    "ordinal_strategy = [\"mean\", \"linear\"]\n",
    "is_PCA = [True]\n",
    "pca_percent_explained_variance = [0.85, 0.9]\n",
    "pca_columns = [\"all_ordinals\", \"concentrations\"]\n",
    "\n",
    "parameters = {\n",
    "    \"lr\": lr, \n",
    "    \"n_epochs\": n_epochs, \n",
    "    \"batch_size\": batch_size,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"dropout\": dropout,\n",
    "    \"layer_def\": layer_def, \n",
    "    \"ordinal_strategy\": ordinal_strategy, \n",
    "    \"categorical_strategy\": categorical_strategy, \n",
    "    \"is_PCA\": is_PCA, \n",
    "    \"pca_percent_explained_variance\": pca_percent_explained_variance, \n",
    "    \"pca_columns\": pca_columns\n",
    "}\n",
    "\n",
    "# Initialize the best model and score\n",
    "best_model = None\n",
    "best_score = float('inf')\n",
    "best_parameters = {\"lr\": None, \n",
    "    \"n_epochs\": None, \n",
    "    \"batch_size\": None, \n",
    "    \"weight_decay\": None,\n",
    "    \"dropout\": None,\n",
    "    \"layer_def\": None, \n",
    "    \"ordinal_strategy\": None, \n",
    "    \"categorical_strategy\": None, \n",
    "    \"is_PCA\": None, \n",
    "    \"pca_percent_explained_variance\": None, \n",
    "    \"pca_columns\": None\n",
    "}\n",
    "best_models = []\n",
    "\n",
    "\n",
    "# Prepare the K-Fold Cross Validation\n",
    "from sklearn.model_selection import KFold\n",
    "n_splits = 3\n",
    "kf = KFold(n_splits=n_splits, random_state=None, shuffle=False)\n",
    "\n",
    "# Loop through all the parameters\n",
    "for lr, n_epochs, batch_size, weight_decay, dropout, layer_def, ordinal_strategy, categorical_strategy, is_PCA, pca_percent_explained_variance, pca_columns in product(\n",
    "    parameters[\"lr\"], \n",
    "    parameters[\"n_epochs\"], \n",
    "    parameters[\"batch_size\"], \n",
    "    parameters[\"weight_decay\"],\n",
    "    parameters[\"dropout\"],\n",
    "    parameters[\"layer_def\"], \n",
    "    parameters[\"ordinal_strategy\"], \n",
    "    parameters[\"categorical_strategy\"], \n",
    "    parameters[\"is_PCA\"], \n",
    "    parameters[\"pca_percent_explained_variance\"], \n",
    "    parameters[\"pca_columns\"]\n",
    "):\n",
    "    print(f\"Testing combination: lr={lr}, n_epochs={n_epochs}, batch_size={batch_size}, weight_decay={weight_decay}, dropout={dropout}, layer_def={layer_def}, ordinal_strategy={ordinal_strategy}, categorical_strategy={categorical_strategy}, is_PCA={is_PCA}, pca_percent_explained_variance={pca_percent_explained_variance}, pca_columns={pca_columns}\")\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    # K-Fold Cross Validation\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        X_train_k, X_test_k = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train_k, y_test_k = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        model, current_X_test, current_y_test, test_dataloader, loss_fn = create_and_train(X_train_k, X_test_k, y_train_k, y_test_k, \n",
    "                                                        layer_def, ordinal_strategy, categorical_strategy, is_PCA, \n",
    "                                                        pca_percent_explained_variance, pca_columns, activation, \n",
    "                                                        lr, weight_decay, dropout, n_epochs, batch_size, visualize=False)  \n",
    "        \n",
    "        score += test_loop(test_dataloader, model, loss_fn)\n",
    "        \n",
    "    score /= n_splits\n",
    "    print(\"\\n Mean Scores: \", score, \"\\n\")\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "        best_parameters[\"lr\"] = lr\n",
    "        best_parameters[\"n_epochs\"] = n_epochs\n",
    "        best_parameters[\"batch_size\"] = batch_size\n",
    "        best_parameters[\"weight_decay\"] = weight_decay\n",
    "        best_parameters[\"dropout\"] = dropout\n",
    "        best_parameters[\"layer_def\"] = layer_def\n",
    "        best_parameters[\"ordinal_strategy\"] = ordinal_strategy\n",
    "        best_parameters[\"categorical_strategy\"] = categorical_strategy\n",
    "        best_parameters[\"is_PCA\"] = is_PCA\n",
    "        best_parameters[\"pca_percent_explained_variance\"] = pca_percent_explained_variance\n",
    "        best_parameters[\"pca_columns\"] = pca_columns\n",
    "    \n",
    "    if score < 100:\n",
    "        best_models.append({\"model\": model, \"score\": score, \"parameters\": {\"lr\": lr, \"n_epochs\": n_epochs, \"batch_size\": batch_size, \"weight_decay\": weight_decay, \"dropout\": dropout, \"layer_def\": layer_def, \"ordinal_strategy\": ordinal_strategy, \"categorical_strategy\": categorical_strategy, \"is_PCA\": is_PCA, \"pca_percent_explained_variance\": pca_percent_explained_variance, \"pca_columns\": pca_columns}})\n",
    "\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Best score: \", best_score)\n",
    "print(\"Best models: \", best_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: 75.573953 \n",
      "\n",
      "75.5739526805691\n"
     ]
    }
   ],
   "source": [
    "# Test the best model on the test set\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "# Best parameters\n",
    "best_parameters = {'lr': 0.01, 'n_epochs': 50, 'batch_size': 4, 'weight_decay': 0.01, 'dropout': False, 'layer_def': [4, 4], 'ordinal_strategy': 'mean', 'categorical_strategy': 'logistic', 'is_PCA': True, 'pca_percent_explained_variance': 0.9, 'pca_columns': 'all_ordinals'}\n",
    "#Best score:  82.85544540008891\n",
    "\n",
    "best_model, best_X_test, best_y_test, best_test_dataloader, best_loss_fn = create_and_train(X_train, X_test, y_train, y_test, \n",
    "                                                        best_parameters[\"layer_def\"], best_parameters[\"ordinal_strategy\"], \n",
    "                                                        best_parameters[\"categorical_strategy\"], \n",
    "                                                        best_parameters[\"pca_percent_explained_variance\"], \n",
    "                                                        best_parameters[\"pca_columns\"], nn.ReLU, \n",
    "                                                        best_parameters[\"lr\"], best_parameters[\"weight_decay\"], best_parameters[\"dropout\"],\n",
    "                                                        best_parameters[\"n_epochs\"], \n",
    "                                                        best_parameters[\"batch_size\"], scaler_strategy=\"standard\", visualize=False) \n",
    "\n",
    "mse = test_loop(best_test_dataloader, best_model, best_loss_fn, visualize=True)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best hyperparameters for neural network\n",
    "\n",
    "- PCA percent explained variance = 0.9\n",
    "\n",
    "- PCA columns: all ordinals\n",
    "\n",
    "- Validation MSE = 82.85544540008891\n",
    "\n",
    "- Learning Rate: 0.01\n",
    "\n",
    "- Weight Decay: 0.01\n",
    "\n",
    "- Number of Epochs: 50\n",
    "\n",
    "- Dropout: False\n",
    "\n",
    "- Batch Size: 4\n",
    "\n",
    "- Layers: 2 hidden layers of 4 neurones each\n",
    "\n",
    "- Ordinal Strategy: mean\n",
    "\n",
    "- Categorical Strategy: logistic\n",
    "\n",
    "- MSE on test set: 75.5739526805691\n",
    "\n",
    "- Scaler: standardization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
